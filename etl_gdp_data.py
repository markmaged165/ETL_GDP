# -*- coding: utf-8 -*-
"""etl_GDP_DATA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1LHjJNpDnAtcpfS6FvyC6fb1oS2Ih4cu5
"""

# Code for ETL operations on Country-GDP data

# Importing the required libraries

def extract(url, table_attribs):
    ''' This function extracts the required
    information from the website and saves it to a dataframe. The
    function returns the dataframe for further processing. '''

    return df

def transform(df):
    ''' This function converts the GDP information from Currency
    format to float value, transforms the information of GDP from
    USD (Millions) to USD (Billions) rounding to 2 decimal places.
    The function returns the transformed dataframe.'''

    return df

def load_to_csv(df, csv_path):
    ''' This function saves the final dataframe as a `CSV` file
    in the provided path. Function returns nothing.'''

def load_to_db(df, sql_connection, table_name):
    ''' This function saves the final dataframe as a database table
    with the provided name. Function returns nothing.'''

def run_query(query_statement, sql_connection):
    ''' This function runs the stated query on the database table and
    prints the output on the terminal. Function returns nothing. '''

def log_progress(message):
    ''' This function logs the mentioned message at a given stage of the code execution to a log file. Function returns nothing'''

''' Here, you define the required entities and call the relevant
functions in the correct order to complete the project. Note that this
portion is not inside any function.'''

from bs4 import BeautifulSoup
import requests
import pandas as pd
import numpy as np
import sqlite3
from datetime import datetime

url = 'https://web.archive.org/web/20230902185326/https://en.wikipedia.org/wiki/List_of_countries_by_GDP_%28nominal%29'
table_attribs = ["Country", "GDP_USD_millions"]
db_name = 'World_Economies.db'
table_name = 'Countries_by_GDP'
csv_path = '/home/data/Countries_by_GDP.csv'



def extract(url, table_attribs):
    page = requests.get(url).text
    data = BeautifulSoup(page,'html.parser')
    df = pd.DataFrame(columns=table_attribs)
    tables = data.find_all('tbody')
    rows = tables[2].find_all('tr')
    for row in rows:
        col = row.find_all('td')
        if len(col)!=0:
            if col[0].find('a') is not None and 'â€”' not in col[2]:
                data_dict = {"Country": col[0].a.contents[0],
                             "GDP_USD_millions": col[2].contents[0]}
                df1 = pd.DataFrame(data_dict, index=[0])
                df = pd.concat([df,df1], ignore_index=True)
    return df

print(extract(url, table_attribs).head())

df=extract(url,table_attribs)

df.info()

df['GDP_USD_millions'].str.replace(',','')

def transform(df):
    df['GDP_USD_millions']=df['GDP_USD_millions'].str.replace(',','').astype(float)
    df['GDP_USD_millions']=np.round(df['GDP_USD_millions']/1000,2)
    df.rename(columns={'GDP_USD_millions':'GDP_USD_billions'},inplace=True)
    return df

print(transform(df).head())

df.info()

def load_to_csv(df, csv_path):
  df.to_csv(csv_path)

load_to_csv(df,csv_path)

def load_to_db(df, sql_connection, table_name):
  df.to_sql(table_name,sql_connection,if_exists='replace', index=False)

conn = sqlite3.connect(db_name)

load_to_db(df,conn,table_name)

def run_query(query_statement, sql_connection):
  print(query_statement)
  ret=pd.read_sql(sql=query_statement,con=sql_connection)
  print(ret)

run_query('SELECT * from Countries_by_GDP \
 where GDP_USD_billions > 100   ',conn)

conn.close()

